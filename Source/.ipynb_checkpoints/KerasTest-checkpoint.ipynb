{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from dog_images import DogImages\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tibetan_terrier\n"
     ]
    }
   ],
   "source": [
    "picsize = 224\n",
    "# Step 1: Get List of Dogs\n",
    "lst = [x[0] for x in os.walk('../Images')]\n",
    "lst_dogs = [a.replace('../Images/', '') for a in lst[1:]]\n",
    "\n",
    "dog_images = DogImages(lst_dogs, picsize)\n",
    "# dog_images.generate_img_files()\n",
    "train_imgs = dog_images.load_images('train')\n",
    "test_imgs = dog_images.load_images('test')\n",
    "Xtest = test_imgs[0]\n",
    "Ytest = test_imgs[1]\n",
    "Xtrain = train_imgs[0]\n",
    "Ytrain = train_imgs[1]\n",
    "\n",
    "lst = [x[0] for x in os.walk('../Images')]\n",
    "lst_dogs = [a[a.index('-')+1:] for a in lst[1:]]\n",
    "print(lst_dogs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31662, 150528)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_pro = np.zeros(Ytrain.shape)\n",
    "Xtest_pro = np.zeros(Ytest.shape)\n",
    "\n",
    "Xtrain_pre = np.zeros(Ytrain.shape)\n",
    "Xtest_pre = np.zeros(Ytest.shape)\n",
    "\n",
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_function(X, y):\n",
    "    Xhold = X.copy()\n",
    "    Yhold = y.copy()\n",
    "    new = np.array([i for i in range(Xhold.shape[0])])\n",
    "    np.random.shuffle(new)\n",
    "    for i, n in enumerate(new):\n",
    "        X[i, :] = Xhold[n, :]\n",
    "        y[i, :] = Yhold[n, :]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest, Ytest = shuffle_function(Xtest, Ytest)\n",
    "Xtrain, Ytrain = shuffle_function(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def my_generator(X, y, batch_size):\n",
    "    # Create empty arrays to contain batch of features and labels#\n",
    "    batch_features = np.zeros((batch_size, 224, 224, 3))\n",
    "    batch_labels = np.zeros((batch_size,y.shape[1]))\n",
    "    features = X.shape[0]\n",
    "    indices = []\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            # choose random index in features\n",
    "            try:\n",
    "                index = indices[0]\n",
    "                indices = indices[1:]\n",
    "            except:\n",
    "                indices = [a for a in range(X.shape[0] - 1)]\n",
    "                random.shuffle(indices)\n",
    "                index = indices[0]\n",
    "                indices = indices[1:]\n",
    "            batch_features[i] = X[index,:].reshape(1,224,224,3)\n",
    "            batch_labels[i] = y[index,:]\n",
    "        yield batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               491640    \n",
      "=================================================================\n",
      "Total params: 134,752,184\n",
      "Trainable params: 491,640\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n",
      "989\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2145s - loss: 3.9266  \n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2144s - loss: 3.0484  \n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2142s - loss: 2.8154  \n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2141s - loss: 2.5842  \n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2142s - loss: 2.4766  \n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2142s - loss: 2.3914  \n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2141s - loss: 2.2198  \n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2142s - loss: 2.2890  \n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2142s - loss: 2.1987  \n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2142s - loss: 2.2446  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5e9dcfc7f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "# create the base pre-trained model\n",
    "# base_model = InceptionV3(weights='imagenet', include_top=True)#\n",
    "base_model = VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "# add a global spatial average pooling \n",
    "base_model.layers.pop()\n",
    "# x = base_model.output\n",
    "x = base_model.layers[-1].output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "# x = Dense(1000, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 120 classes\n",
    "predictions = Dense(120, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "for layer in model.layers[:len(model.layers[:])-1]:\n",
    "    layer.trainable = False\n",
    "model.summary()\n",
    "\n",
    "'''\n",
    "This whole mess was due to include_top=False\n",
    "# # first: train only the top layers (which were randomly initialized)\n",
    "# # i.e. freeze all convolutional InceptionV3 layers\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# # compile the model (should be done *after* setting layers to non-trainable)\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\"\n",
    "\n",
    "# # train the model on the new data for a few epochs\n",
    "# Y_train = np.argmax(Ytrain)\n",
    "# model.fit_generator(my_generator(Xtrain, Ytrain, 200), samples_per_epoch=50, nb_epoch=10)\n",
    "\n",
    "# # at this point, the top layers are well trained and we can start fine-tuning\n",
    "# # convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# # and train the remaining top layers.\n",
    "\n",
    "# # let's visualize layer names and layer indices to see how many layers\n",
    "# # we should freeze:\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#    print(i, layer.name)\n",
    "\n",
    "# # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# # the first 249 layers and unfreeze the rest:\n",
    "# for layer in model.layers[:249]:\n",
    "#    layer.trainable = False\n",
    "# for layer in model.layers[249:]:\n",
    "#    layer.trainable = True\n",
    "'''\n",
    "# for layer in model.layers[:len(model.layers[:])-1]:\n",
    "#     layer.trainable = False\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy')\n",
    "bs = 32\n",
    "samp = int(Xtrain.shape[0]/bs)\n",
    "print(samp)\n",
    "model.fit_generator(my_generator(Xtrain, Ytrain, 32), samples_per_epoch=1000, nb_epoch=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9498/9498 [==============================] - 890s   \n",
      "ding!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    preds = model.predict(X_test, verbose=1)\n",
    "    print('ding!')\n",
    "except:\n",
    "    X_test = np.zeros((Xtest.shape[0],224,224,3))\n",
    "    for i in range(Xtest.shape[0]):\n",
    "        X_test[i,:,:,:] = Xtest[i,:].reshape(1,224,224,3)\n",
    "        print('\\r {:.0f}%'.format(100*(i+1)/Xtest.shape[0]), end=\"\")\n",
    "    preds = model.predict(X_test, verbose=1)\n",
    "    print('ding!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.evaluate of <keras.engine.training.Model object at 0x7f5e9dd9eb70>>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "model.evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47083596546641399"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((np.argmax(preds,1) == np.argmax(Ytest,1)))/Ytest.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5,   7,  89, ...,  86,  16, 101])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(preds,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([99,  7, 89, ..., 32, 65, 98])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Ytest,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9498/9498 [==============================] - 1007s  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.26670131625113"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
